{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88733310-77ec-4503-b59f-c992db612ba3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7fd96-62a4-40e6-a6fd-9be668521796",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d0e647-1195-4a02-85aa-32a2790d96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nimbro_utils.lazy import read_json, escape, format_number\n",
    "from nimbro_utils.lazy import remove_ansi_escape, draw_text, show_image, save_image # for saving as image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5ec3d-dbc5-4df1-bcf9-a7ea2b614be0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62ec328-5561-4051-aeba-35f29ffc76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(base_path, model_name_to_eval_dict, weights=None, latex=False):\n",
    "    rows = []\n",
    "\n",
    "    # These experiments were conducted with an infinite number of retry attempts until a valid structured description was obtained.\n",
    "    # We changed the evaluation protocol to allow for a maximum of four attempts in order to accommodate models that rarely or never succeed.\n",
    "    inf_retries = [\n",
    "        \"claude_sonnet_4/fo_2025_06_09_01_25_22_237_label_match\",\n",
    "        \"gemini_2_5_flash_high/fo_2025_08_28_14_21_16_422_label_match\",\n",
    "        \"gemini_2_5_flash_low/fo_2025_08_28_14_24_39_880_label_match\",\n",
    "        \"gemini_2_5_flash_medium/fo_2025_08_28_14_42_54_220_label_match\",\n",
    "        \"gemini_2_5_flash_none/fo_2025_08_28_15_08_42_343_label_match\",\n",
    "        \"gemini_2_5_flash_preview/fo_2025_06_09_01_43_46_408_label_match\",\n",
    "        \"gemini_2_5_pro_high/fo_2025_08_28_15_26_51_137_label_match\",\n",
    "        \"gemini_2_5_pro_none/fo_2025_08_28_15_51_46_277_label_match\",\n",
    "        \"gemini_2_5_pro_preview/fo_2025_06_09_02_04_38_468_label_match\",\n",
    "        \"glm_4_5_reason/fo_2025_08_28_17_06_55_532_label_match\",\n",
    "        \"gpt_4_1/fo_2025_06_09_09_54_44_572_label_match\",\n",
    "        \"gpt_4_1_mini/fo_2025_06_09_10_01_01_783_label_match\",\n",
    "        \"gpt_4_1_nano/fo_2025_06_09_11_31_50_761_label_match\",\n",
    "        \"gpt_5_high/fo_2025_08_28_16_19_05_062_label_match\",\n",
    "        \"gpt_5_mini_none/fo_2025_08_28_17_00_14_730_label_match\",\n",
    "        \"gpt_5_nano_high/fo_2025_08_28_17_37_39_974_label_match\",\n",
    "        \"gpt_5_nano_none/fo_2025_08_28_17_53_26_811_label_match\",\n",
    "        \"gpt_5_none/fo_2025_08_28_18_06_02_775_label_match\",\n",
    "        \"grok_4/fo_2025_08_28_19_05_16_834_label_match\",\n",
    "        \"internvl_3_5_2b_none/fo_2025_08_28_18_57_59_521_label_match\",\n",
    "        \"internvl_3_5_2b_reason/fo_2025_08_28_20_36_39_816_label_match\",\n",
    "        \"internvl_3_5_4b_reason/fo_2025_08_28_19_20_26_476_label_match\",\n",
    "        \"internvl_3_5_20b_a4b_reason/fo_2025_08_29_18_37_44_078_label_match\",\n",
    "        \"internvl_3_5_30b_a3b_none/fo_2025_08_28_19_33_16_248_label_match\",\n",
    "        \"internvl_3_5_30b_a3b_reason/fo_2025_08_28_19_44_42_109_label_match\",\n",
    "        \"internvl_3_5_38b_reason/fo_2025_08_28_20_10_41_190_label_match\",\n",
    "        \"mistral_medium_3_1_temp_high/fo_2025_08_28_21_07_24_394_label_match\",\n",
    "        \"mistral_medium_3_1_temp_low/fo_2025_08_28_21_19_05_965_label_match\",\n",
    "        \"ovis_2_5_9b_none/fo_2025_08_26_14_37_31_222_label_match\",\n",
    "        \"ovis_2_5_9b_reason/fo_2025_08_28_21_36_05_082_label_match\",\n",
    "        \"claude_sonnet_4/fo_2025_06_08_22_11_36_197_label_match\",\n",
    "        \"gemini_2_5_flash_high/fo_2025_08_28_22_08_17_562_label_match\",\n",
    "        \"gemini_2_5_flash_low/fo_2025_08_29_15_11_06_237_label_match\",\n",
    "        \"gemini_2_5_flash_medium/fo_2025_08_29_15_18_30_354_label_match\",\n",
    "        \"gemini_2_5_flash_none/fo_2025_08_25_15_21_08_854_label_match\",\n",
    "        \"gemini_2_5_flash_preview/fo_2025_06_08_22_43_08_886_label_match\",\n",
    "        \"gemini_2_5_pro_high/fo_2025_08_29_15_26_11_360_label_match\",\n",
    "        \"gemini_2_5_pro_none/fo_2025_08_28_22_25_19_287_label_match\",\n",
    "        \"gemini_2_5_pro_preview/fo_2025_06_08_22_35_47_157_label_match\",\n",
    "        \"glm_4_5_reason/fo_2025_08_28_23_09_06_888_label_match\",\n",
    "        \"gpt_4_1/fo_2025_06_08_22_29_53_001_label_match\",\n",
    "        \"gpt_4_1_mini/fo_2025_06_08_22_47_47_312_label_match\",\n",
    "        \"gpt_4_1_nano/fo_2025_06_08_22_52_38_103_label_match\",\n",
    "        \"gpt_5_high/fo_2025_08_29_15_56_15_093_label_match\",\n",
    "        \"gpt_5_mini_high/fo_2025_08_29_16_08_33_024_label_match\",\n",
    "        \"gpt_5_mini_none/fo_2025_08_28_22_54_34_989_label_match\",\n",
    "        \"gpt_5_nano_high/fo_2025_08_29_16_21_15_467_label_match\",\n",
    "        \"gpt_5_nano_none/fo_2025_08_29_16_41_22_600_label_match\",\n",
    "        \"gpt_5_none/fo_2025_08_28_22_43_40_097_label_match\",\n",
    "        \"grok_4/fo_2025_08_28_23_01_10_250_label_match\",\n",
    "        \"internvl_3_5_2b_none/fo_2025_08_28_23_22_43_290_label_match\",\n",
    "        \"internvl_3_5_2b_reason/fo_2025_08_29_16_50_49_757_label_match\",\n",
    "        \"internvl_3_5_4b_none/fo_2025_08_29_17_40_43_317_label_match\",\n",
    "        \"internvl_3_5_4b_reason/fo_2025_08_29_17_47_57_187_label_match\",\n",
    "        \"internvl_3_5_30b_a3b_none/fo_2025_08_29_17_00_39_604_label_match\",\n",
    "        \"internvl_3_5_30b_a3b_reason/fo_2025_08_29_17_20_54_905_label_match\",\n",
    "        \"internvl_3_5_38b_reason/fo_2025_08_29_17_31_43_513_label_match\",\n",
    "        \"mistral_medium_3_1_temp_high/fo_2025_08_28_23_42_47_130_label_match\",\n",
    "        \"mistral_medium_3_1_temp_low/fo_2025_08_29_17_57_35_128_label_match\",\n",
    "        \"ovis_2_5_9b_none/fo_2025_08_28_23_51_45_603_label_match\",\n",
    "        \"ovis_2_5_9b_reason/fo_2025_08_29_18_04_13_326_label_match\",\n",
    "    ]\n",
    "\n",
    "    longest_name = 0\n",
    "    if isinstance(model_name_to_eval_dict, list):\n",
    "        considered_models = []\n",
    "        for model in model_name_to_eval_dict[0]:\n",
    "            for i in range(len(model_name_to_eval_dict) - 1):\n",
    "                if model not in model_name_to_eval_dict[1 + i]:\n",
    "                    break\n",
    "            else:\n",
    "                longest_name = max(longest_name, len(model))\n",
    "                considered_models.append(model)\n",
    "        num_considered_models = len(considered_models)\n",
    "\n",
    "        num_weights = len(weights)\n",
    "        sum_weights = sum(weights)\n",
    "        weights = [w / sum_weights for w in weights]\n",
    "\n",
    "        all_failure = [0 for _ in range(num_considered_models)]\n",
    "        all_attempts = [0 for _ in range(num_considered_models)]\n",
    "        all_described_instances = [0 for _ in range(num_considered_models)]\n",
    "        all_description_time = [0 for _ in range(num_considered_models)]\n",
    "        all_matched = [0 for _ in range(num_considered_models)]\n",
    "        all_mAP = [0 for _ in range(num_considered_models)]\n",
    "        all_precision = [0 for _ in range(num_considered_models)]\n",
    "        all_recall = [0 for _ in range(num_considered_models)]\n",
    "        all_fscore = [0 for _ in range(num_considered_models)]\n",
    "\n",
    "        for i, model in enumerate(considered_models):\n",
    "            for j, w in enumerate(weights):\n",
    "                longest_name = max(longest_name, len(model))\n",
    "                file_path = os.path.join(base_path[j].rstrip(os.path.sep), model_name_to_eval_dict[j][model].lstrip(os.path.sep), \"evaluation.json\")\n",
    "                file_path = os.path.abspath(file_path)\n",
    "                try:\n",
    "                    success, message, results = read_json(file_path=file_path)\n",
    "                    assert success, f\"{model}: {message}\"\n",
    "                    if not success:\n",
    "                        raise Exception(message)\n",
    "                    if model_name_to_eval_dict[j][model] in inf_retries:\n",
    "                        all_failure[i] += np.nan\n",
    "                        all_attempts[i] += np.nan\n",
    "                    else:\n",
    "                        all_failure[i] += results['images'].get('described_instances_NaN', 0.0) * w\n",
    "                        all_attempts[i] += results['images'].get('failures_structured_description_mean', np.nan) * w\n",
    "                    all_described_instances[i] += results['images'].get('detected_instances_mean', np.nan) * w\n",
    "                    # all_description_time[i] += results['images'].get('time_description_mean') * w\n",
    "                    all_description_time[i] += results['images'].get('time_description_median', np.nan) * w\n",
    "                    # all_matched[i] += results['images'].get('label_matching_accept_mean', np.nan) * w)\n",
    "                    all_matched[i] += (results['images'].get('label_matching_accept_mean', np.nan) / results['images'].get('detected_instances_mean', np.nan)) * w\n",
    "                    all_mAP[i] += results['results'].get('performance_metrics', {}).get('mAP', np.nan) * w\n",
    "                    all_precision[i] += results['results'].get('performance_metrics', {}).get('precision', np.nan) * w\n",
    "                    all_recall[i] += results['results'].get('performance_metrics', {}).get('recall', np.nan) * w\n",
    "                    all_fscore[i] += results['results'].get('performance_metrics', {}).get('fscore', np.nan) * w\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Failed obtaining '{model}' results from '{file_path}': {repr(e)}\")\n",
    "\n",
    "    else:\n",
    "        considered_models = list(model_name_to_eval_dict.keys())\n",
    "\n",
    "        all_failure = []\n",
    "        all_attempts = []\n",
    "        all_described_instances = []\n",
    "        all_description_time = []\n",
    "        all_matched = []\n",
    "        all_mAP = []\n",
    "        all_precision = []\n",
    "        all_recall = []\n",
    "        all_fscore = []\n",
    "\n",
    "        for model in model_name_to_eval_dict:\n",
    "            longest_name = max(longest_name, len(model))\n",
    "            file_path = os.path.join(base_path.rstrip(os.path.sep), model_name_to_eval_dict[model].lstrip(os.path.sep), \"evaluation.json\")\n",
    "            file_path = os.path.abspath(file_path)\n",
    "            try:\n",
    "                success, message, results = read_json(file_path=file_path)\n",
    "                assert success, f\"{model}: {message}\"\n",
    "                if not success:\n",
    "                    raise Exception(message)\n",
    "                if model_name_to_eval_dict[model] in inf_retries:\n",
    "                    all_failure.append(np.nan)\n",
    "                    all_attempts.append(np.nan)\n",
    "                else:\n",
    "                    all_failure.append(results['images'].get('described_instances_NaN', 0.0))\n",
    "                    all_attempts.append(results['images'].get('failures_structured_description_mean', np.nan))\n",
    "                all_described_instances.append(results['images'].get('detected_instances_mean', np.nan))\n",
    "                # all_description_time.append(results['images'].get('time_description_mean'))\n",
    "                all_description_time.append(results['images'].get('time_description_median', np.nan))\n",
    "                # all_matched.append(results['images'].get('label_matching_accept_mean', np.nan))\n",
    "                all_matched.append(results['images'].get('label_matching_accept_mean', np.nan) / all_described_instances[-1])\n",
    "                all_mAP.append(results['results'].get('performance_metrics', {}).get('mAP', np.nan))\n",
    "                all_precision.append(results['results'].get('performance_metrics', {}).get('precision', np.nan))\n",
    "                all_recall.append(results['results'].get('performance_metrics', {}).get('recall', np.nan))\n",
    "                all_fscore.append(results['results'].get('performance_metrics', {}).get('fscore', np.nan))\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Failed obtaining '{model}' results from '{file_path}': {repr(e)}\")\n",
    "\n",
    "    try:\n",
    "        best_failure = np.nanargmin(all_failure)\n",
    "        worst_failure = np.nanargmax(all_failure)\n",
    "    except:\n",
    "        best_failure = None\n",
    "        worst_failure = None\n",
    "\n",
    "    try:\n",
    "        best_attempts = np.nanargmin(all_attempts)\n",
    "        worst_attempts = np.nanargmax(all_attempts)\n",
    "    except:\n",
    "        best_attempts = None\n",
    "        worst_attempts = None\n",
    "\n",
    "    try:\n",
    "        best_described_instances = np.nanargmax(all_described_instances)\n",
    "        worst_described_instances = np.nanargmin(all_described_instances)\n",
    "    except:\n",
    "        best_described_instances = None\n",
    "        worst_described_instances = None\n",
    "\n",
    "    try:\n",
    "        best_description_time = np.nanargmin(all_description_time)\n",
    "        worst_description_time = np.nanargmax(all_description_time)\n",
    "    except:\n",
    "        best_description_time = None\n",
    "        worst_description_time = None\n",
    "\n",
    "    # try:\n",
    "    #     best_matched = np.nanargmax(all_matched)\n",
    "    #     worst_matched = np.nanargmin(all_matched)\n",
    "    # except:\n",
    "    #     best_matched = None\n",
    "    #     worst_matched = None\n",
    "\n",
    "    try:\n",
    "        best_mAP = np.nanargmax(all_mAP)\n",
    "        worst_mAP = np.nanargmin(all_mAP)\n",
    "    except:\n",
    "        best_mAP = None\n",
    "        worst_mAP = None\n",
    "\n",
    "    try:\n",
    "        best_precision = np.nanargmax(all_precision)\n",
    "        worst_precision = np.nanargmin(all_precision)\n",
    "    except:\n",
    "        best_precision = None\n",
    "        worst_precision = None\n",
    "\n",
    "    try:\n",
    "        best_recall = np.nanargmax(all_recall)\n",
    "        worst_recall = np.nanargmin(all_recall)\n",
    "    except:\n",
    "        best_recall = None\n",
    "        worst_recall = None\n",
    "\n",
    "    try:\n",
    "        best_fscore = np.nanargmax(all_fscore)\n",
    "        worst_fscore = np.nanargmin(all_fscore)\n",
    "    except:\n",
    "        best_fscore = None\n",
    "        worst_fscore = None\n",
    "\n",
    "    for i, model in enumerate(considered_models):\n",
    "        name = f\"{model}{' ' * (longest_name - len(model))}\"\n",
    "\n",
    "        failure = format_number(all_failure[i], integers=1, decimals=2, signed=False)\n",
    "        attempts = format_number(all_attempts[i], integers=1, decimals=2, signed=False)\n",
    "        described_instances = format_number(all_described_instances[i], integers=2, decimals=1, signed=False)\n",
    "        description_time = format_number(all_description_time[i], integers=3, decimals=1, signed=False)\n",
    "        description_time = f\"{description_time}s\"\n",
    "        # matched = format_number(all_matched[i], integers=2, decimals=1, signed=False)\n",
    "        matched = format_number(all_matched[i], integers=1, decimals=2, signed=False)\n",
    "        mAP = format_number(all_mAP[i], integers=1, decimals=3, signed=False)\n",
    "        precision = format_number(all_precision[i], integers=1, decimals=3, signed=False)\n",
    "        recall = format_number(all_recall[i], integers=1, decimals=3, signed=False)\n",
    "        fscore = format_number(all_fscore[i], integers=1, decimals=3, signed=False)\n",
    "\n",
    "        if latex:\n",
    "            if best_described_instances is not None:\n",
    "                if all_described_instances[i] == all_described_instances[best_described_instances]:\n",
    "                    described_instances = r\"\\bf{\" + described_instances + r\"}\"\n",
    "                else:\n",
    "                    described_instances = f\"    {described_instances} \"\n",
    "\n",
    "            if best_description_time is not None:\n",
    "                if all_description_time[i] == all_description_time[best_description_time]:\n",
    "                    description_time = r\"\\bf{\" + description_time + r\"}\"\n",
    "                else:\n",
    "                    description_time = f\"    {description_time} \"\n",
    "\n",
    "            if best_mAP is not None:\n",
    "                if all_mAP[i] == all_mAP[best_mAP]:\n",
    "                    mAP = r\"\\bf{\" + mAP + r\"}\"\n",
    "                else:\n",
    "                    mAP = f\"    {mAP} \"\n",
    "\n",
    "            if best_precision is not None:\n",
    "                if all_precision[i] == all_precision[best_precision]:\n",
    "                    precision = r\"\\bf{\" + precision + r\"}\"\n",
    "                else:\n",
    "                    precision = f\"    {precision} \"\n",
    "\n",
    "            if best_recall is not None:\n",
    "                if all_recall[i] == all_recall[best_recall]:\n",
    "                    recall = r\"\\bf{\" + recall + r\"}\"\n",
    "                else:\n",
    "                    recall = f\"    {recall} \"\n",
    "\n",
    "            if best_fscore is not None:\n",
    "                if all_fscore[i] == all_fscore[best_fscore]:\n",
    "                    fscore = r\"\\bf{\" + fscore + r\"}\"\n",
    "                else:\n",
    "                    fscore = f\"    {fscore} \"\n",
    "\n",
    "            if isinstance(model_name_to_eval_dict, list):\n",
    "                row = f\"& {model}{' ' * (longest_name - len(model))} & {described_instances} & {description_time} & {mAP} & {precision} & {recall} & {fscore} \\\\\\\\ % {' '.join(os.path.join(base_path[j], model_name_to_eval_dict[j][model]) for j in range(num_weights))})\"\n",
    "            else:\n",
    "                row = f\"& {model}{' ' * (longest_name - len(model))} & {described_instances} & {description_time} & {mAP} & {precision} & {recall} & {fscore} \\\\\\\\ % {model_name_to_eval_dict[model]}\"\n",
    "        else:\n",
    "            if best_failure is not None:\n",
    "                if all_failure[i] == all_failure[best_failure]:\n",
    "                    failure = f\"{escape['bold']}{escape['blue']}{failure}{escape['end']}\"\n",
    "                elif all_failure[i] == all_failure[worst_failure]:\n",
    "                    failure = f\"{escape['bold']}{escape['red']}{failure}{escape['end']}\"\n",
    "\n",
    "            if best_attempts is not None:\n",
    "                if all_attempts[i] == all_attempts[best_attempts]:\n",
    "                    attempts = f\"{escape['bold']}{escape['blue']}{attempts}{escape['end']}\"\n",
    "                elif all_attempts[i] == all_attempts[worst_attempts]:\n",
    "                    attempts = f\"{escape['bold']}{escape['red']}{attempts}{escape['end']}\"\n",
    "\n",
    "            if best_described_instances is not None:\n",
    "                if all_described_instances[i] == all_described_instances[best_described_instances]:\n",
    "                    described_instances = f\"{escape['bold']}{escape['blue']}{described_instances}{escape['end']}\"\n",
    "                elif all_described_instances[i] == all_described_instances[worst_described_instances]:\n",
    "                    described_instances = f\"{escape['bold']}{escape['red']}{described_instances}{escape['end']}\"\n",
    "\n",
    "            if best_description_time is not None:\n",
    "                if all_description_time[i] == all_description_time[best_description_time]:\n",
    "                    description_time = f\"{escape['bold']}{escape['blue']}{description_time}{escape['end']}\"\n",
    "                elif all_description_time[i] == all_description_time[worst_description_time]:\n",
    "                    description_time = f\"{escape['bold']}{escape['red']}{description_time}{escape['end']}\"\n",
    "\n",
    "            # if best_matched is not None:\n",
    "            #     if all_matched[i] == all_matched[best_matched]:\n",
    "            #         matched = f\"{escape['bold']}{escape['blue']}{matched}{escape['end']}\"\n",
    "            #     elif all_matched[i] == all_matched[worst_matched]:\n",
    "            #         matched = f\"{escape['bold']}{escape['red']}{matched}{escape['end']}\"\n",
    "\n",
    "            if best_mAP is not None:\n",
    "                if all_mAP[i] == all_mAP[best_mAP]:\n",
    "                    mAP = f\"{escape['bold']}{escape['blue']}{mAP}{escape['end']}\"\n",
    "                elif all_mAP[i] == all_mAP[worst_mAP]:\n",
    "                    mAP = f\"{escape['bold']}{escape['red']}{mAP}{escape['end']}\"\n",
    "\n",
    "            if best_precision is not None:\n",
    "                if all_precision[i] == all_precision[best_precision]:\n",
    "                    precision = f\"{escape['bold']}{escape['blue']}{precision}{escape['end']}\"\n",
    "                elif all_precision[i] == all_precision[worst_precision]:\n",
    "                    precision = f\"{escape['bold']}{escape['red']}{precision}{escape['end']}\"\n",
    "\n",
    "            if best_recall is not None:\n",
    "                if all_recall[i] == all_recall[best_recall]:\n",
    "                    recall = f\"{escape['bold']}{escape['blue']}{recall}{escape['end']}\"\n",
    "                elif all_recall[i] == all_recall[worst_recall]:\n",
    "                    recall = f\"{escape['bold']}{escape['red']}{recall}{escape['end']}\"\n",
    "\n",
    "            if best_fscore is not None:\n",
    "                if all_fscore[i] == all_fscore[best_fscore]:\n",
    "                    fscore = f\"{escape['bold']}{escape['blue']}{fscore}{escape['end']}\"\n",
    "                elif all_fscore[i] == all_fscore[worst_fscore]:\n",
    "                    fscore = f\"{escape['bold']}{escape['red']}{fscore}{escape['end']}\"\n",
    "\n",
    "            row = f\"{name} | {fscore} | {recall} | {precision} | {mAP} || {described_instances} | {matched} | {description_time} || {failure} | {attempts}\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    if latex:\n",
    "        result = [f\"% {base_path}\"]\n",
    "    else:\n",
    "        header = f\"Model{' ' * (longest_name - len('model'))} |  F1   |  Rec. | Prec. |  mAP  || Ins. | Mat. |  Time  || Fail | Ret.\"\n",
    "        result = [header, len(header) * \"-\"]\n",
    "\n",
    "    # order = np.argsort(np.array(all_failure))\n",
    "    # order = np.argsort(np.array(all_attempts))\n",
    "    # order = np.argsort(-np.array(all_described_instances))\n",
    "    # order = np.argsort(np.array(all_description_time))\n",
    "    # order = np.argsort(-np.array(all_mAP))\n",
    "    # order = np.argsort(-np.array(all_matched))\n",
    "    # order = np.argsort(-np.array(all_precision))\n",
    "    # order = np.argsort(-np.array(all_recall))\n",
    "    order = np.argsort(-np.array(all_fscore))\n",
    "    for i in order:\n",
    "        result.append(rows[i])\n",
    "\n",
    "    return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b388a28-5543-44be-94fd-cd85db3c7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(text, suffix, path=\".\"):\n",
    "    text_normal = remove_ansi_escape(text)\n",
    "    image = draw_text(\n",
    "        image=np.zeros((int(round(len(text.splitlines()) * 24.8)), 1315), dtype=np.uint8),\n",
    "        text=text_normal,\n",
    "        anchor=(0,0),\n",
    "        font_path=\"/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf\",\n",
    "        font_size=22,\n",
    "        # background_color=(255, 255, 255),\n",
    "        # text_color=(0, 0, 0)\n",
    "    )\n",
    "    # show_image(image, 700)\n",
    "    image_path = save_image(image=image, suffix=suffix, path=path)\n",
    "    print(f\"Results saved to '{os.path.abspath(image_path)}'\")\n",
    "    text_path = image_path.replace(\".png\", \".txt\")\n",
    "    with open(text_path, \"a\") as f:\n",
    "        f.write(text_normal)\n",
    "        # f.write(text + \"\\n\")\n",
    "    print(f\"Results saved to '{os.path.abspath(text_path)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec993ae8-df6f-4ed0-b650-9a603149cfb4",
   "metadata": {},
   "source": [
    "### Description Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8157b-03b4-477e-8a97-a455db3f0e24",
   "metadata": {},
   "source": [
    "#### COCO 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ed4f9b-8cfe-4101-a206-24584e546939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        |  F1   |  Rec. | Prec. |  mAP  || Ins. | Mat. |  Time  || Fail | Ret.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Gemini 2.5 Pro (high)        | \u001b[1m\u001b[94m0.541\u001b[0m | 0.489 | 0.606 | 0.338 || 11.4 | 0.50 |  14.5s ||  nan |  nan\n",
      "Gemini 2.5 Pro (preview)     | 0.537 | 0.487 | 0.599 | \u001b[1m\u001b[94m0.350\u001b[0m || 11.1 | 0.51 |  13.3s ||  nan |  nan\n",
      "Gemini 2.5 Pro               | 0.537 | 0.487 | 0.598 | 0.337 || 11.4 | 0.50 |  14.7s ||  nan |  nan\n",
      "GLM 4.5V (think)             | 0.526 | 0.445 | 0.642 | 0.334 ||  8.2 | 0.60 |  14.9s ||  nan |  nan\n",
      "Grok 4                       | 0.524 | \u001b[1m\u001b[94m0.531\u001b[0m | 0.518 | 0.340 || 12.1 | 0.59 |  58.2s ||  nan |  nan\n",
      "GPT-5 chat                   | 0.524 | 0.449 | 0.628 | 0.336 ||  9.6 | 0.52 |   4.5s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "InternVL 3.5 38B (think)     | 0.523 | 0.464 | 0.599 | 0.336 ||  9.8 | 0.55 |  59.1s ||  nan |  nan\n",
      "Gemini 2.5 Flash (medium)    | 0.520 | 0.487 | 0.558 | 0.323 || 12.7 | 0.48 |   6.6s ||  nan |  nan\n",
      "Gemini 2.5 Flash Lite (high) | 0.520 | 0.449 | 0.616 | 0.316 ||  8.9 | 0.57 |   9.5s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.05\n",
      "Gemini 2.5 Flash (low)       | 0.518 | 0.479 | 0.563 | 0.326 || 12.1 | 0.49 |   5.7s ||  nan |  nan\n",
      "InternVL 3.5 20B A4B (think) | 0.518 | 0.457 | 0.597 | 0.312 ||  9.2 | 0.58 |  40.1s ||  nan |  nan\n",
      "Gemini 2.5 Flash (high)      | 0.515 | 0.493 | 0.540 | 0.327 || 13.0 | 0.49 |   7.6s ||  nan |  nan\n",
      "Qwen3-VL 235B A22B (think)   | 0.513 | 0.459 | 0.580 | 0.324 ||  8.5 | 0.66 |   5.0s || 0.00 | 0.14\n",
      "GLM 4.5V                     | 0.510 | 0.412 | 0.670 | 0.328 ||  7.4 | 0.60 |  15.9s || 0.03 | 0.19\n",
      "GPT-4o chat                  | 0.509 | 0.482 | 0.539 | 0.336 || 12.1 | 0.52 |   6.8s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Gemini 2.5 Flash             | 0.509 | 0.453 | 0.579 | 0.321 ||  9.5 | 0.58 |   2.9s ||  nan |  nan\n",
      "GPT-4.1                      | 0.508 | 0.472 | 0.550 | 0.330 || 10.5 | 0.57 |   7.5s ||  nan |  nan\n",
      "Gemini 2.5 Flash (preview)   | 0.507 | 0.444 | 0.590 | 0.323 ||  9.2 | 0.57 |   3.2s ||  nan |  nan\n",
      "GPT-5 mini                   | 0.505 | 0.501 | 0.509 | 0.327 || 13.7 | 0.50 |  27.9s ||  nan |  nan\n",
      "GPT-4.1 mini                 | 0.504 | 0.426 | 0.618 | 0.297 ||  7.8 | 0.62 |   4.3s ||  nan |  nan\n",
      "o4 mini (high)               | 0.504 | 0.457 | 0.562 | 0.310 || 10.3 | 0.55 |  21.9s || 0.00 | 0.13\n",
      "Grok 4 Fast (high)           | 0.504 | 0.485 | 0.525 | 0.313 || 12.7 | 0.52 |   9.1s || 0.01 | 0.51\n",
      "InternVL 3.5 4B (think)      | 0.501 | 0.432 | 0.597 | 0.292 ||  8.9 | 0.57 |  35.0s ||  nan |  nan\n",
      "GPT-5 mini (high)            | 0.501 | 0.476 | 0.529 | 0.297 || 13.9 | 0.46 |  82.4s || 0.02 | 0.10\n",
      "Qwen3-VL 235B A22B           | 0.500 | 0.456 | 0.554 | 0.329 ||  9.4 | 0.62 |   6.1s || 0.01 | 0.10\n",
      "o3 (high)                    | 0.499 | 0.496 | 0.503 | 0.324 || 13.5 | 0.52 |  83.3s || 0.01 | 0.06\n",
      "OVIS 2.5 9B                  | 0.499 | 0.399 | 0.667 | 0.316 ||  7.0 | 0.60 |   6.5s ||  nan |  nan\n",
      "InternVL 3.5 30B A3B         | 0.499 | 0.410 | 0.635 | 0.306 ||  7.1 | 0.64 |  35.1s ||  nan |  nan\n",
      "Qwen3-VL 30B A3B (think)     | 0.495 | 0.391 | \u001b[1m\u001b[94m0.677\u001b[0m | 0.276 || \u001b[1m\u001b[91m 5.8\u001b[0m | 0.70 |  25.4s || 0.01 | 0.09\n",
      "Grok 4 Fast                  | 0.495 | 0.480 | 0.510 | 0.304 || 13.0 | 0.52 |   9.1s || 0.03 | 0.54\n",
      "Claude Sonnet 4.5            | 0.491 | 0.394 | 0.650 | 0.294 ||  7.4 | 0.57 |   5.3s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.00\n",
      "InternVL 3.5 30B A3B (think) | 0.490 | 0.415 | 0.600 | 0.289 ||  9.2 | 0.52 |  38.6s ||  nan |  nan\n",
      "Mistral Medium 3.1 (t=1.00)  | 0.489 | 0.408 | 0.611 | 0.313 ||  8.4 | 0.56 |   2.9s ||  nan |  nan\n",
      "OVIS 2.5 9B (think)          | 0.489 | 0.394 | 0.644 | 0.301 ||  8.1 | 0.53 |  24.0s ||  nan |  nan\n",
      "GPT-5 (high)                 | 0.487 | 0.510 | 0.466 | 0.311 || \u001b[1m\u001b[94m16.7\u001b[0m | 0.46 |  88.6s ||  nan |  nan\n",
      "GPT-5 nano (high)            | 0.487 | 0.415 | 0.589 | 0.297 ||  9.4 | 0.53 |  44.2s ||  nan |  nan\n",
      "GPT-5                        | 0.486 | 0.503 | 0.471 | 0.311 || 15.8 | 0.47 |  47.6s ||  nan |  nan\n",
      "GPT-5 nano                   | 0.485 | 0.416 | 0.581 | 0.289 ||  9.2 | 0.54 |  24.1s ||  nan |  nan\n",
      "Claude Sonnet 4.5 (high)     | 0.481 | 0.408 | 0.588 | 0.283 ||  8.4 | 0.58 |  16.6s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "Gemma 27B                    | 0.478 | 0.418 | 0.558 | 0.284 || 10.6 | 0.50 |   9.5s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Claude Sonnet 4              | 0.472 | 0.372 | 0.646 | 0.291 ||  7.9 | 0.51 |   5.5s ||  nan |  nan\n",
      "Qwen-VL Plus                 | 0.472 | 0.368 | 0.659 | 0.270 ||  6.8 | 0.59 | \u001b[1m\u001b[94m  2.8s\u001b[0m || 0.02 | 0.53\n",
      "Mistral Medium 3.1 (t=0.15)  | 0.472 | 0.418 | 0.541 | 0.308 ||  9.3 | 0.59 |   3.0s ||  nan |  nan\n",
      "InternVL 3.5 2B (think)      | 0.470 | 0.388 | 0.595 | 0.294 ||  7.9 | 0.58 |  27.7s ||  nan |  nan\n",
      "InternVL 3.5 2B              | 0.466 | 0.386 | 0.588 | 0.288 ||  6.8 | 0.67 | \u001b[1m\u001b[91m124.8s\u001b[0m ||  nan |  nan\n",
      "Gemma 12B                    | 0.462 | 0.384 | 0.578 | 0.291 ||  9.3 | 0.50 |  12.5s || 0.00 | 0.37\n",
      "Claude Haiku 4.5 (high)      | 0.461 | 0.396 | 0.551 | 0.258 || 11.1 | 0.45 |  14.7s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Claude Haiku 4.5             | 0.459 | 0.379 | 0.582 | 0.256 ||  9.8 | 0.47 |   3.6s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Gemini 2.5 Flash Lite        | 0.447 | 0.435 | 0.460 | 0.304 || 10.1 | 0.66 |   2.8s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "Qwen3-VL 30B A3B             | 0.432 | 0.408 | 0.459 | 0.275 ||  9.6 | 0.67 |   4.4s || 0.03 | 0.50\n",
      "Gemma 4B                     | 0.430 | 0.323 | 0.641 | 0.255 ||  6.4 | 0.55 |   3.3s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "Qwen3-VL 32B                 | 0.420 | 0.390 | 0.457 | 0.248 || 13.0 | 0.58 |  12.7s || 0.20 | 1.45\n",
      "GPT-4.1 nano                 | 0.415 | 0.341 | 0.530 | 0.232 ||  6.5 | 0.69 |   3.5s ||  nan |  nan\n",
      "Qwen3-VL 8B                  | 0.366 | 0.394 | \u001b[1m\u001b[91m0.343\u001b[0m | 0.279 ||  9.9 | 0.82 |   6.3s || 0.01 | 0.05\n",
      "Qwen3-VL 8B (think)          | \u001b[1m\u001b[91m0.333\u001b[0m | \u001b[1m\u001b[91m0.224\u001b[0m | 0.646 | \u001b[1m\u001b[91m0.180\u001b[0m ||  7.0 | 0.61 |  72.0s || \u001b[1m\u001b[91m0.43\u001b[0m | \u001b[1m\u001b[91m1.64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "base_path_coco = \"./../../data/keep/coco\"\n",
    "\n",
    "model_name_to_eval_dict_coco = {\n",
    "    'Claude Haiku 4.5 (high)' : \"claude_haiku_4_5_high/fo_2025_10_22_23_41_29_127_label_match\",\n",
    "    'Claude Haiku 4.5' : \"claude_haiku_4_5_none/fo_2025_10_23_00_02_45_014_label_match\",\n",
    "    'Claude Sonnet 4': \"claude_sonnet_4/fo_2025_06_09_01_25_22_237_label_match\", # *\n",
    "    'Claude Sonnet 4.5 (high)' : \"claude_sonnet_4_5_high/fo_2025_10_23_00_15_50_267_label_match\",\n",
    "    'Claude Sonnet 4.5' : \"claude_sonnet_4_5_none/fo_2025_10_23_00_27_26_085_label_match\",\n",
    "    'Gemini 2.5 Flash (high)': \"gemini_2_5_flash_high/fo_2025_08_28_14_21_16_422_label_match\", # *\n",
    "    'Gemini 2.5 Flash Lite (high)': \"gemini_2_5_flash_lite_high/fo_2025_09_24_17_21_36_580_label_match\",\n",
    "    'Gemini 2.5 Flash Lite': \"gemini_2_5_flash_lite_none/fo_2025_09_24_16_32_10_614_label_match\",\n",
    "    'Gemini 2.5 Flash (low)': \"gemini_2_5_flash_low/fo_2025_08_28_14_24_39_880_label_match\", # *\n",
    "    'Gemini 2.5 Flash (medium)': \"gemini_2_5_flash_medium/fo_2025_08_28_14_42_54_220_label_match\", # *\n",
    "    'Gemini 2.5 Flash': \"gemini_2_5_flash_none/fo_2025_08_28_15_08_42_343_label_match\", # *\n",
    "    'Gemini 2.5 Flash (preview)': \"gemini_2_5_flash_preview/fo_2025_06_09_01_43_46_408_label_match\", # *\n",
    "    'Gemini 2.5 Pro (high)': \"gemini_2_5_pro_high/fo_2025_08_28_15_26_51_137_label_match\", # *\n",
    "    'Gemini 2.5 Pro': \"gemini_2_5_pro_none/fo_2025_08_28_15_51_46_277_label_match\", # *\n",
    "    'Gemini 2.5 Pro (preview)': \"gemini_2_5_pro_preview/fo_2025_06_09_02_04_38_468_label_match\", # *\n",
    "    'Gemma 4B': \"gemma_4b/fo_2025_09_29_17_03_54_913_label_match\",\n",
    "    'Gemma 12B': \"gemma_12b/fo_2025_09_29_16_41_04_519_label_match\",\n",
    "    'Gemma 27B': \"gemma_27b/fo_2025_09_29_16_54_08_445_label_match\",\n",
    "    'GLM 4.5V': \"glm_4_5_none/fo_2025_09_29_17_11_17_392_label_match\",\n",
    "    'GLM 4.5V (think)': \"glm_4_5_reason/fo_2025_08_28_17_06_55_532_label_match\", # *\n",
    "    'GPT-4.1': \"gpt_4_1/fo_2025_06_09_09_54_44_572_label_match\", # *\n",
    "    'GPT-4.1 mini': \"gpt_4_1_mini/fo_2025_06_09_10_01_01_783_label_match\", # *\n",
    "    'GPT-4.1 nano': \"gpt_4_1_nano/fo_2025_06_09_11_31_50_761_label_match\", # *\n",
    "    'GPT-4o chat': \"gpt_4o_chat/fo_2025_10_30_19_40_47_232_label_match\",\n",
    "    'GPT-5 chat': \"gpt_5_chat/fo_2025_10_30_19_52_52_810_label_match\",\n",
    "    'GPT-5 (high)': \"gpt_5_high/fo_2025_08_28_16_19_05_062_label_match\", # *\n",
    "    'GPT-5 mini (high)': \"gpt_5_mini_high/fo_2025_09_26_12_06_47_231_label_match\",\n",
    "    'GPT-5 mini': \"gpt_5_mini_none/fo_2025_08_28_17_00_14_730_label_match\", # *\n",
    "    'GPT-5 nano (high)': \"gpt_5_nano_high/fo_2025_08_28_17_37_39_974_label_match\", # *\n",
    "    'GPT-5 nano': \"gpt_5_nano_none/fo_2025_08_28_17_53_26_811_label_match\", # *\n",
    "    'GPT-5': \"gpt_5_none/fo_2025_08_28_18_06_02_775_label_match\", # *\n",
    "    'Grok 4': \"grok_4/fo_2025_08_28_19_05_16_834_label_match\", # *\n",
    "    'Grok 4 Fast (high)' : \"grok_4_fast_high/fo_2025_10_23_00_50_15_109_label_match\",\n",
    "    'Grok 4 Fast' : \"grok_4_fast_none/fo_2025_10_23_01_23_51_679_label_match\",\n",
    "    'InternVL 3.5 2B': \"internvl_3_5_2b_none/fo_2025_08_28_18_57_59_521_label_match\", # *\n",
    "    'InternVL 3.5 2B (think)': \"internvl_3_5_2b_reason/fo_2025_08_28_20_36_39_816_label_match\", # *\n",
    "    'InternVL 3.5 4B (think)': \"internvl_3_5_4b_reason/fo_2025_08_28_19_20_26_476_label_match\", # *\n",
    "    'InternVL 3.5 20B A4B (think)': \"internvl_3_5_20b_a4b_reason/fo_2025_08_29_18_37_44_078_label_match\", # *\n",
    "    'InternVL 3.5 30B A3B': \"internvl_3_5_30b_a3b_none/fo_2025_08_28_19_33_16_248_label_match\", # *\n",
    "    'InternVL 3.5 30B A3B (think)': \"internvl_3_5_30b_a3b_reason/fo_2025_08_28_19_44_42_109_label_match\", # *\n",
    "    'InternVL 3.5 38B (think)': \"internvl_3_5_38b_reason/fo_2025_08_28_20_10_41_190_label_match\", # *\n",
    "    'Mistral Medium 3.1 (t=1.00)': \"mistral_medium_3_1_temp_high/fo_2025_08_28_21_07_24_394_label_match\", # *\n",
    "    'Mistral Medium 3.1 (t=0.15)': \"mistral_medium_3_1_temp_low/fo_2025_08_28_21_19_05_965_label_match\", # *\n",
    "    'o3 (high)': \"o3_high/fo_2025_10_30_20_14_18_106_label_match\",\n",
    "    'o4 mini (high)': \"o4_mini_high/fo_2025_10_30_20_37_13_076_label_match\",\n",
    "    'OVIS 2.5 9B ': \"ovis_2_5_9b_none/fo_2025_08_26_14_37_31_222_label_match\", # *\n",
    "    'OVIS 2.5 9B (think)': \"ovis_2_5_9b_reason/fo_2025_08_28_21_36_05_082_label_match\", # *\n",
    "    'Qwen3-VL 8B' : \"qwen_3_vl_8b_none/fo_2025_10_23_02_08_49_040_label_match\",\n",
    "    'Qwen3-VL 8B (think)' : \"qwen_3_vl_8b_reason/fo_2025_10_23_02_19_45_610_label_match\",\n",
    "    'Qwen3-VL 30B A3B' : \"qwen_3_vl_30b_a3b_none/fo_2025_10_23_01_40_31_045_label_match\",\n",
    "    'Qwen3-VL 30B A3B (think)' : \"qwen_3_vl_30b_a3b_reason/fo_2025_10_23_01_55_14_372_label_match\",\n",
    "    'Qwen3-VL 32B': \"qwen_3_vl_32b_none/fo_2025_10_30_21_01_38_004_label_match\",\n",
    "    'Qwen3-VL 235B A22B': \"qwen_3_vl_235b_A22b_none/fo_2025_09_29_17_24_19_003_label_match\",\n",
    "    'Qwen3-VL 235B A22B (think)': \"qwen_3_vl_235b_A22b_reason/fo_2025_09_29_17_35_57_241_label_match\",\n",
    "    'Qwen-VL Plus': \"qwen_vl_plus/fo_2025_09_29_17_54_53_346_label_match\",\n",
    "}\n",
    "\n",
    "# *infinite retries\n",
    "\n",
    "text = write_results(base_path_coco, model_name_to_eval_dict_coco, latex=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53522c53-ab31-4ca1-9b4e-d2a5f5288542",
   "metadata": {},
   "source": [
    "Models are sorted in descending order by F-1 score.<br>\n",
    "Best model(s) per column is/are highlighted in blue.<br>\n",
    "Worst model(s) per column is/are highlighted in red.<br>\n",
    "\n",
    "Legend:\n",
    "- F1: The achieved F-1 score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Rec.: The achieved recall score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Prec.: The achieved precision score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- mAP: The achieved mAP score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Ins.: The average number of object instances in a valid structured description per image.<br>\n",
    "- Mat.: The ratio of matched detections by the label matching procedure over all detections.<br>\n",
    "- Time: The median time to generate a valid structured description over all images.<br>\n",
    "- Fail: The rate of invalid structured descriptions after all (4) generation attempts.<br>\n",
    "- Ret.: The average number of retry attempts to generate a valid structured description per image (0 to 3).<br>\n",
    " \n",
    "Remarks:\n",
    "- Models where the last two columns report nan were evaluated with an infinite and untracked number of retry attempts, until a valid structured description was obtained.<br>\n",
    "- All models were used and interpreted at best effort, limiting parallel usage, attempting to extract JSON from within markdown tags or reasoning content, etc.<br>\n",
    "- Reasons for failed attempts may include rate limits, content moderation, timeouts, reaching max. token limits, etc.<br>\n",
    "- All reported times may heavily be affected by the used hardware, rate limits, server load, etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ef3027-bcf6-4f36-a460-d0ccfff2eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ros2 run vlm_gist fiftyone_eval \" + \" \".join([f'\"{os.path.abspath(os.path.join(base_path_coco.rstrip(os.path.sep), model_name_to_eval_dict_coco[model].lstrip(os.path.sep)))}\"' for model in model_name_to_eval_dict_coco]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627a0877-68b1-4883-94f5-e08f93ee3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_40_0764ddf4_coco.png'\n",
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_40_0764ddf4_coco.txt'\n"
     ]
    }
   ],
   "source": [
    "save_results(text=text, suffix=\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3800087-8415-42ec-8334-0f166b53a0f6",
   "metadata": {},
   "source": [
    "#### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8b6705-c52f-47c4-93e5-489cbb773eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        |  F1   |  Rec. | Prec. |  mAP  || Ins. | Mat. |  Time  || Fail | Ret.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Gemini 2.5 Pro               | \u001b[1m\u001b[94m0.464\u001b[0m | \u001b[1m\u001b[94m0.417\u001b[0m | 0.523 | 0.363 || 14.7 | 1.00 |  16.0s ||  nan |  nan\n",
      "Gemini 2.5 Pro (high)        | 0.460 | 0.415 | 0.515 | \u001b[1m\u001b[94m0.366\u001b[0m || 14.8 | 1.00 |  17.7s ||  nan |  nan\n",
      "Gemini 2.5 Pro (preview)     | 0.451 | 0.402 | 0.515 | 0.357 || 14.3 | 1.00 |  14.9s ||  nan |  nan\n",
      "Gemini 2.5 Flash (low)       | 0.435 | 0.395 | 0.485 | 0.344 || 15.0 | 1.00 |   7.1s ||  nan |  nan\n",
      "o4 mini (high)               | 0.432 | 0.381 | 0.498 | 0.337 || 14.1 | 1.00 |  24.6s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.02\n",
      "Grok 4                       | 0.428 | 0.385 | 0.482 | 0.340 || 14.7 | 1.00 |  34.7s ||  nan |  nan\n",
      "GPT-5 mini (high)            | 0.422 | 0.401 | 0.445 | 0.342 || 16.6 | 1.00 |  82.7s ||  nan |  nan\n",
      "GPT-5                        | 0.418 | 0.413 | 0.424 | 0.352 || 17.9 | 1.00 |  54.2s ||  nan |  nan\n",
      "OVIS 2.5 9B (think)          | 0.415 | 0.318 | 0.596 | 0.281 ||  9.8 | 1.00 |  32.0s ||  nan |  nan\n",
      "Gemini 2.5 Flash (high)      | 0.415 | 0.379 | 0.458 | 0.324 || 15.3 | 1.00 |   7.4s ||  nan |  nan\n",
      "GPT-5 mini                   | 0.414 | 0.388 | 0.444 | 0.338 || 16.1 | 1.00 |  32.7s ||  nan |  nan\n",
      "o3 (high)                    | 0.413 | 0.393 | 0.435 | 0.338 || 16.6 | 1.00 |  78.9s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.03\n",
      "Gemini 2.5 Flash Lite (high) | 0.412 | 0.340 | 0.522 | 0.291 || 12.0 | 1.00 |  11.9s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.02\n",
      "GPT-5 chat                   | 0.412 | 0.343 | 0.516 | 0.302 || 12.2 | 1.00 |   6.0s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "GPT-4o chat                  | 0.411 | 0.374 | 0.456 | 0.318 || 15.1 | 1.00 |   8.5s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "GPT-4.1 mini                 | 0.410 | 0.319 | 0.571 | 0.279 || 10.3 | 1.00 |   6.0s ||  nan |  nan\n",
      "GPT-4.1                      | 0.407 | 0.356 | 0.476 | 0.308 || 13.8 | 1.00 |   8.7s ||  nan |  nan\n",
      "Grok 4 Fast (high)           | 0.407 | 0.377 | 0.443 | 0.323 || 15.7 | 1.00 |   9.0s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.38\n",
      "GPT-5 (high)                 | 0.407 | 0.413 | 0.400 | 0.348 || \u001b[1m\u001b[94m19.0\u001b[0m | 1.00 | 101.4s ||  nan |  nan\n",
      "Gemini 2.5 Flash             | 0.406 | 0.345 | 0.495 | 0.305 || 12.8 | 1.00 |   3.6s ||  nan |  nan\n",
      "InternVL 3.5 38B (think)     | 0.405 | 0.332 | 0.521 | 0.295 || 11.7 | 1.00 |  58.3s ||  nan |  nan\n",
      "Qwen3-VL 30B A3B (think)     | 0.402 | 0.292 | \u001b[1m\u001b[94m0.644\u001b[0m | 0.258 ||  8.3 | 1.00 |  28.9s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.16\n",
      "Gemini 2.5 Flash (preview)   | 0.401 | 0.341 | 0.486 | 0.297 || 12.9 | 1.00 |   4.0s ||  nan |  nan\n",
      "Gemini 2.5 Flash (medium)    | 0.400 | 0.366 | 0.441 | 0.311 || 15.3 | 1.00 |   7.2s ||  nan |  nan\n",
      "GLM 4.5V (think)             | 0.400 | 0.312 | 0.555 | 0.276 || 10.4 | 1.00 |  14.9s ||  nan |  nan\n",
      "Qwen3-VL 235B A22B           | 0.397 | 0.320 | 0.521 | 0.278 || 11.3 | 1.00 |   8.0s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.06\n",
      "Qwen3-VL 235B A22B (think)   | 0.392 | 0.329 | 0.483 | 0.286 || 12.6 | 1.00 |   8.3s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.14\n",
      "Grok 4 Fast                  | 0.387 | 0.357 | 0.424 | 0.309 || 15.5 | 1.00 |   7.8s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.16\n",
      "GPT-5 nano (high)            | 0.383 | 0.319 | 0.478 | 0.280 || 12.3 | 1.00 |  51.3s ||  nan |  nan\n",
      "InternVL 3.5 30B A3B (think) | 0.378 | 0.302 | 0.506 | 0.259 || 11.0 | 1.00 |  38.5s ||  nan |  nan\n",
      "GPT-5 nano                   | 0.373 | 0.306 | 0.479 | 0.267 || 11.8 | 1.00 |  28.9s ||  nan |  nan\n",
      "Qwen3-VL 8B                  | 0.373 | 0.284 | 0.544 | 0.249 ||  9.7 | 1.00 |   4.0s || 0.02 | 0.05\n",
      "Qwen3-VL 32B                 | 0.372 | 0.301 | 0.485 | 0.259 || 13.8 | 1.00 |  14.4s || 0.17 | \u001b[1m\u001b[91m0.86\u001b[0m\n",
      "GLM 4.5V                     | 0.368 | 0.279 | 0.538 | 0.243 ||  9.9 | 1.00 |  16.0s || 0.03 | 0.22\n",
      "OVIS 2.5 9B                  | 0.365 | 0.267 | 0.573 | 0.239 ||  8.6 | 1.00 |   8.0s ||  nan |  nan\n",
      "InternVL 3.5 4B (think)      | 0.363 | 0.284 | 0.503 | 0.246 || 10.4 | 1.00 |  36.1s ||  nan |  nan\n",
      "Mistral Medium 3.1 (t=0.15)  | 0.351 | 0.285 | 0.458 | 0.247 || 11.5 | 1.00 |   3.7s ||  nan |  nan\n",
      "Qwen-VL Plus                 | 0.346 | 0.260 | 0.520 | 0.227 ||  9.2 | 1.00 |   4.4s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.34\n",
      "Gemini 2.5 Flash Lite        | 0.345 | 0.282 | 0.445 | 0.241 || 11.7 | 1.00 | \u001b[1m\u001b[94m  3.1s\u001b[0m || \u001b[1m\u001b[94m0.00\u001b[0m | 0.02\n",
      "InternVL 3.5 30B A3B         | 0.344 | 0.254 | 0.533 | 0.222 ||  8.8 | 1.00 |  42.2s ||  nan |  nan\n",
      "InternVL 3.5 4B              | 0.343 | 0.262 | 0.495 | 0.229 ||  9.8 | 1.00 |  37.1s ||  nan |  nan\n",
      "InternVL 3.5 2B (think)      | 0.337 | 0.258 | 0.486 | 0.220 ||  9.8 | 1.00 |  33.1s ||  nan |  nan\n",
      "Claude Sonnet 4.5 (high)     | 0.334 | 0.279 | 0.414 | 0.233 || 12.4 | 1.00 |  17.5s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Qwen3-VL 30B A3B             | 0.330 | 0.244 | 0.512 | 0.215 ||  9.5 | 1.00 |  11.3s || 0.08 | 0.59\n",
      "Qwen3-VL 8B (think)          | 0.327 | 0.240 | 0.512 | 0.209 || 10.6 | 1.00 |  97.3s || \u001b[1m\u001b[91m0.19\u001b[0m | 0.84\n",
      "Gemma 27B                    | 0.327 | 0.267 | 0.421 | 0.229 || 11.7 | 1.00 |  11.4s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Mistral Medium 3.1 (t=1.00)  | 0.327 | 0.284 | 0.383 | 0.247 || 13.7 | 1.00 |   4.0s ||  nan |  nan\n",
      "Claude Sonnet 4.5            | 0.325 | 0.258 | 0.437 | 0.227 || 10.9 | 1.00 |   7.3s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Claude Sonnet 4              | 0.321 | 0.250 | 0.451 | 0.216 || 10.2 | 1.00 |   6.3s ||  nan |  nan\n",
      "Gemma 12B                    | 0.314 | 0.239 | 0.456 | 0.205 || 10.1 | 1.00 |  14.1s || 0.05 | 0.56\n",
      "GPT-4.1 nano                 | 0.310 | 0.229 | 0.480 | 0.201 ||  8.8 | 1.00 |   4.6s ||  nan |  nan\n",
      "Claude Haiku 4.5 (high)      | 0.296 | 0.263 | \u001b[1m\u001b[91m0.337\u001b[0m | 0.226 || 14.4 | 1.00 |  15.9s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "InternVL 3.5 2B              | 0.294 | 0.207 | 0.505 | 0.179 || \u001b[1m\u001b[91m 7.5\u001b[0m | 1.00 | \u001b[1m\u001b[91m117.4s\u001b[0m ||  nan |  nan\n",
      "Claude Haiku 4.5             | 0.289 | 0.248 | 0.345 | 0.210 || 13.2 | 1.00 |   4.3s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Gemma 4B                     | \u001b[1m\u001b[91m0.282\u001b[0m | \u001b[1m\u001b[91m0.206\u001b[0m | 0.448 | \u001b[1m\u001b[91m0.179\u001b[0m ||  8.5 | 1.00 |   3.2s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "base_path_custom = \"./../../data/keep/custom\"\n",
    "\n",
    "model_name_to_eval_dict_custom = {\n",
    "    'Claude Haiku 4.5 (high)' : \"claude_haiku_4_5_high/fo_2025_10_22_22_57_47_441_label_match\",\n",
    "    'Claude Haiku 4.5' : \"claude_haiku_4_5_none/fo_2025_10_22_23_00_03_868_label_match\",\n",
    "    'Claude Sonnet 4': \"claude_sonnet_4/fo_2025_06_08_22_11_36_197_label_match\", # *\n",
    "    'Claude Sonnet 4.5 (high)' : \"claude_sonnet_4_5_high/fo_2025_10_22_23_02_34_737_label_match\",\n",
    "    'Claude Sonnet 4.5' : \"claude_sonnet_4_5_none/fo_2025_10_22_23_12_49_545_label_match\",\n",
    "    'Gemini 2.5 Flash (high)': \"gemini_2_5_flash_high/fo_2025_08_28_22_08_17_562_label_match\", # *\n",
    "    'Gemini 2.5 Flash Lite (high)': \"gemini_2_5_flash_lite_high/fo_2025_09_24_12_52_14_681_label_match\",\n",
    "    'Gemini 2.5 Flash Lite': \"gemini_2_5_flash_lite_none/fo_2025_09_24_12_51_42_507_label_match\",\n",
    "    'Gemini 2.5 Flash (low)': \"gemini_2_5_flash_low/fo_2025_08_29_15_11_06_237_label_match\", # *\n",
    "    'Gemini 2.5 Flash (medium)': \"gemini_2_5_flash_medium/fo_2025_08_29_15_18_30_354_label_match\", # *\n",
    "    'Gemini 2.5 Flash': \"gemini_2_5_flash_none/fo_2025_08_25_15_21_08_854_label_match\", # *\n",
    "    'Gemini 2.5 Flash (preview)': \"gemini_2_5_flash_preview/fo_2025_06_08_22_43_08_886_label_match\", # *\n",
    "    'Gemini 2.5 Pro (high)': \"gemini_2_5_pro_high/fo_2025_08_29_15_26_11_360_label_match\", # *\n",
    "    'Gemini 2.5 Pro': \"gemini_2_5_pro_none/fo_2025_08_28_22_25_19_287_label_match\", # *\n",
    "    'Gemini 2.5 Pro (preview)': \"gemini_2_5_pro_preview/fo_2025_06_08_22_35_47_157_label_match\", # *\n",
    "    'Gemma 4B': \"gemma_4b/fo_2025_09_26_12_24_16_991_label_match\",\n",
    "    'Gemma 12B': \"gemma_12b/fo_2025_09_30_13_04_45_707_label_match\",\n",
    "    'Gemma 27B': \"gemma_27b/fo_2025_09_26_12_21_24_437_label_match\",\n",
    "    'GLM 4.5V': \"glm_4_5_none/fo_2025_09_26_12_34_34_430_label_match\",\n",
    "    'GLM 4.5V (think)': \"glm_4_5_reason/fo_2025_08_28_23_09_06_888_label_match\", # *\n",
    "    'GPT-4.1': \"gpt_4_1/fo_2025_06_08_22_29_53_001_label_match\", # *\n",
    "    'GPT-4.1 mini': \"gpt_4_1_mini/fo_2025_06_08_22_47_47_312_label_match\", # *\n",
    "    'GPT-4.1 nano': \"gpt_4_1_nano/fo_2025_06_08_22_52_38_103_label_match\", # *\n",
    "    'GPT-4o chat': \"gpt_4o_chat/fo_2025_10_30_19_00_16_463_label_match\",\n",
    "    'GPT-5 chat': \"gpt_5_chat/fo_2025_10_30_19_10_05_166_label_match\",\n",
    "    'GPT-5 (high)': \"gpt_5_high/fo_2025_08_29_15_56_15_093_label_match\", # *\n",
    "    'GPT-5 mini (high)': \"gpt_5_mini_high/fo_2025_08_29_16_08_33_024_label_match\", # *\n",
    "    'GPT-5 mini': \"gpt_5_mini_none/fo_2025_08_28_22_54_34_989_label_match\", # *\n",
    "    'GPT-5 nano (high)': \"gpt_5_nano_high/fo_2025_08_29_16_21_15_467_label_match\", # *\n",
    "    'GPT-5 nano': \"gpt_5_nano_none/fo_2025_08_29_16_41_22_600_label_match\", # *\n",
    "    'GPT-5': \"gpt_5_none/fo_2025_08_28_22_43_40_097_label_match\", # *\n",
    "    'Grok 4': \"grok_4/fo_2025_08_28_23_01_10_250_label_match\", # *\n",
    "    'Grok 4 Fast (high)' : \"grok_4_fast_high/fo_2025_10_22_23_15_41_940_label_match\",\n",
    "    'Grok 4 Fast' : \"grok_4_fast_none/fo_2025_10_22_23_18_49_943_label_match\",\n",
    "    'InternVL 3.5 2B': \"internvl_3_5_2b_none/fo_2025_08_28_23_22_43_290_label_match\", # *\n",
    "    'InternVL 3.5 2B (think)': \"internvl_3_5_2b_reason/fo_2025_08_29_16_50_49_757_label_match\", # *\n",
    "    'InternVL 3.5 4B': \"internvl_3_5_4b_none/fo_2025_08_29_17_40_43_317_label_match\", # *\n",
    "    'InternVL 3.5 4B (think)': \"internvl_3_5_4b_reason/fo_2025_08_29_17_47_57_187_label_match\", # *\n",
    "    'InternVL 3.5 30B A3B': \"internvl_3_5_30b_a3b_none/fo_2025_08_29_17_00_39_604_label_match\", # *\n",
    "    'InternVL 3.5 30B A3B (think)': \"internvl_3_5_30b_a3b_reason/fo_2025_08_29_17_20_54_905_label_match\", # *\n",
    "    'InternVL 3.5 38B (think)': \"internvl_3_5_38b_reason/fo_2025_08_29_17_31_43_513_label_match\", # *\n",
    "    'Mistral Medium 3.1 (t=1.00)': \"mistral_medium_3_1_temp_high/fo_2025_08_28_23_42_47_130_label_match\", # *\n",
    "    'Mistral Medium 3.1 (t=0.15)': \"mistral_medium_3_1_temp_low/fo_2025_08_29_17_57_35_128_label_match\", # *\n",
    "    'o3 (high)': \"o3_high/fo_2025_10_30_19_13_20_278_label_match\",\n",
    "    'o4 mini (high)': \"o4_mini_high/fo_2025_10_30_19_16_09_472_label_match\",\n",
    "    'OVIS 2.5 9B': \"ovis_2_5_9b_none/fo_2025_08_28_23_51_45_603_label_match\", # *\n",
    "    'OVIS 2.5 9B (think)': \"ovis_2_5_9b_reason/fo_2025_08_29_18_04_13_326_label_match\", # *\n",
    "    'Qwen3-VL 8B' : \"qwen_3_vl_8b_none/fo_2025_10_22_23_22_50_685_label_match\",\n",
    "    'Qwen3-VL 8B (think)' : \"qwen_3_vl_8b_reason/fo_2025_10_22_23_24_17_799_label_match\",\n",
    "    'Qwen3-VL 30B A3B' : \"qwen_3_vl_30b_a3b_none/fo_2025_10_22_23_20_08_695_label_match\",\n",
    "    'Qwen3-VL 30B A3B (think)' : \"qwen_3_vl_30b_a3b_reason/fo_2025_10_22_23_21_30_376_label_match\",\n",
    "    'Qwen3-VL 32B': \"qwen_3_vl_32b_none/fo_2025_10_30_19_18_02_973_label_match\",\n",
    "    'Qwen3-VL 235B A22B': \"qwen_3_vl_235b_A22b_none/fo_2025_09_26_12_38_16_410_label_match\",\n",
    "    'Qwen3-VL 235B A22B (think)': \"qwen_3_vl_235b_A22b_reason/fo_2025_09_30_13_02_46_896_label_match\",\n",
    "    'Qwen-VL Plus': \"qwen_vl_plus/fo_2025_09_26_12_40_59_911_label_match\",\n",
    "}\n",
    "\n",
    "# *infinite retries\n",
    "\n",
    "text = write_results(base_path_custom, model_name_to_eval_dict_custom, latex=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d2b14-5e84-48ec-9afe-a32a7b676772",
   "metadata": {},
   "source": [
    "Models are sorted in descending order by F-1 score.<br>\n",
    "Best model(s) per column is/are highlighted in blue.<br>\n",
    "Worst model(s) per column is/are highlighted in red.<br>\n",
    "\n",
    "Legend:\n",
    "- F1: The achieved F-1 score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Rec.: The achieved recall score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Prec.: The achieved precision score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- mAP: The achieved mAP score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Ins.: The average number of object instances in a valid structured description per image.<br>\n",
    "- Mat.: The ratio of matched detections by the label matching procedure over all detections.<br>\n",
    "- Time: The median time to generate a valid structured description over all images.<br>\n",
    "- Fail: The rate of invalid structured descriptions after all (4) generation attempts.<br>\n",
    "- Ret.: The average number of retry attempts to generate a valid structured description per image (0 to 3).<br>\n",
    " \n",
    "Remarks:\n",
    "- Models where the last two columns report nan were evaluated with an infinite and untracked number of retry attempts, until a valid structured description was obtained.<br>\n",
    "- All models were used and interpreted at best effort, limiting parallel usage, attempting to extract JSON from within markdown tags or reasoning content, etc.<br>\n",
    "- Reasons for failed attempts may include rate limits, content moderation, timeouts, reaching max. token limits, etc.<br>\n",
    "- All reported times may heavily be affected by the used hardware, rate limits, server load, etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525ec8d2-7752-45a8-9040-cf5d5cc89c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ros2 run vlm_gist fiftyone_eval \" + \" \".join([f'\"{os.path.abspath(os.path.join(base_path_custom.rstrip(os.path.sep), model_name_to_eval_dict_custom[model].lstrip(os.path.sep)))}\"' for model in model_name_to_eval_dict_custom]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a80ac7-feac-4803-bafa-1c2fbacc2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_40_e037e8d9_custom.png'\n",
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_40_e037e8d9_custom.txt'\n"
     ]
    }
   ],
   "source": [
    "save_results(text=text, suffix=\"custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eeb6e3-ad30-4bf8-9623-6e419706e7f9",
   "metadata": {},
   "source": [
    "#### Weighted Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400a799c-d6a8-487c-b090-2ab6f983ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        |  F1   |  Rec. | Prec. |  mAP  || Ins. | Mat. |  Time  || Fail | Ret.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Gemini 2.5 Pro (high)        | \u001b[1m\u001b[94m0.500\u001b[0m | 0.452 | 0.560 | 0.352 || 13.1 | 0.75 |  16.1s ||  nan |  nan\n",
      "Gemini 2.5 Pro               | 0.500 | 0.452 | 0.560 | 0.350 || 13.0 | 0.75 |  15.3s ||  nan |  nan\n",
      "Gemini 2.5 Pro (preview)     | 0.494 | 0.444 | 0.557 | \u001b[1m\u001b[94m0.353\u001b[0m || 12.7 | 0.76 |  14.1s ||  nan |  nan\n",
      "Gemini 2.5 Flash (low)       | 0.477 | 0.437 | 0.524 | 0.335 || 13.5 | 0.75 |   6.4s ||  nan |  nan\n",
      "Grok 4                       | 0.476 | 0.458 | 0.500 | 0.340 || 13.4 | 0.80 |  46.4s ||  nan |  nan\n",
      "o4 mini (high)               | 0.468 | 0.419 | 0.530 | 0.323 || 12.2 | 0.78 |  23.3s || 0.00 | 0.07\n",
      "GPT-5 chat                   | 0.468 | 0.396 | 0.572 | 0.319 || 10.9 | 0.76 |   5.2s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Gemini 2.5 Flash Lite (high) | 0.466 | 0.395 | 0.569 | 0.303 || 10.5 | 0.79 |  10.7s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.03\n",
      "Gemini 2.5 Flash (high)      | 0.465 | 0.436 | 0.499 | 0.325 || 14.1 | 0.75 |   7.5s ||  nan |  nan\n",
      "InternVL 3.5 38B (think)     | 0.464 | 0.398 | 0.560 | 0.315 || 10.8 | 0.78 |  58.7s ||  nan |  nan\n",
      "GLM 4.5V (think)             | 0.463 | 0.379 | 0.599 | 0.305 ||  9.3 | 0.80 |  14.9s ||  nan |  nan\n",
      "GPT-5 mini (high)            | 0.461 | 0.438 | 0.487 | 0.319 || 15.2 | 0.73 |  82.6s ||  nan |  nan\n",
      "GPT-4o chat                  | 0.460 | 0.428 | 0.498 | 0.327 || 13.6 | 0.76 |   7.7s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Gemini 2.5 Flash (medium)    | 0.460 | 0.426 | 0.499 | 0.317 || 14.0 | 0.74 |   6.9s ||  nan |  nan\n",
      "GPT-5 mini                   | 0.460 | 0.445 | 0.476 | 0.332 || 14.9 | 0.75 |  30.3s ||  nan |  nan\n",
      "GPT-4.1                      | 0.458 | 0.414 | 0.513 | 0.319 || 12.1 | 0.79 |   8.1s ||  nan |  nan\n",
      "Gemini 2.5 Flash             | 0.457 | 0.399 | 0.537 | 0.313 || 11.1 | 0.79 |   3.2s ||  nan |  nan\n",
      "GPT-4.1 mini                 | 0.457 | 0.373 | 0.595 | 0.288 ||  9.0 | 0.81 |   5.2s ||  nan |  nan\n",
      "o3 (high)                    | 0.456 | 0.445 | 0.469 | 0.331 || 15.0 | 0.76 |  81.1s || 0.00 | 0.04\n",
      "Grok 4 Fast (high)           | 0.456 | 0.431 | 0.484 | 0.318 || 14.2 | 0.76 |   9.0s || 0.01 | 0.44\n",
      "Gemini 2.5 Flash (preview)   | 0.454 | 0.393 | 0.538 | 0.310 || 11.1 | 0.79 |   3.6s ||  nan |  nan\n",
      "GPT-5                        | 0.452 | 0.458 | 0.448 | 0.331 || 16.8 | 0.74 |  50.9s ||  nan |  nan\n",
      "OVIS 2.5 9B (think)          | 0.452 | 0.356 | 0.620 | 0.291 ||  9.0 | 0.77 |  28.0s ||  nan |  nan\n",
      "Qwen3-VL 235B A22B (think)   | 0.452 | 0.394 | 0.531 | 0.305 || 10.5 | 0.83 |   6.6s || 0.00 | 0.14\n",
      "Qwen3-VL 30B A3B (think)     | 0.449 | 0.341 | \u001b[1m\u001b[94m0.661\u001b[0m | 0.267 || \u001b[1m\u001b[91m 7.1\u001b[0m | 0.85 |  27.1s || 0.00 | 0.12\n",
      "Qwen3-VL 235B A22B           | 0.449 | 0.388 | 0.538 | 0.304 || 10.3 | 0.81 |   7.1s || 0.01 | 0.08\n",
      "GPT-5 (high)                 | 0.447 | \u001b[1m\u001b[94m0.462\u001b[0m | \u001b[1m\u001b[91m0.433\u001b[0m | 0.330 || \u001b[1m\u001b[94m17.8\u001b[0m | 0.73 |  95.0s ||  nan |  nan\n",
      "Grok 4 Fast                  | 0.441 | 0.418 | 0.467 | 0.306 || 14.3 | 0.76 |   8.4s || 0.02 | 0.35\n",
      "GLM 4.5V                     | 0.439 | 0.346 | 0.604 | 0.286 ||  8.6 | 0.80 |  15.9s || 0.03 | 0.20\n",
      "GPT-5 nano (high)            | 0.435 | 0.367 | 0.533 | 0.289 || 10.8 | 0.76 |  47.7s ||  nan |  nan\n",
      "InternVL 3.5 30B A3B (think) | 0.434 | 0.359 | 0.553 | 0.274 || 10.1 | 0.76 |  38.6s ||  nan |  nan\n",
      "InternVL 3.5 4B (think)      | 0.432 | 0.358 | 0.550 | 0.269 ||  9.6 | 0.78 |  35.5s ||  nan |  nan\n",
      "GPT-5 nano                   | 0.429 | 0.361 | 0.530 | 0.278 || 10.5 | 0.77 |  26.5s ||  nan |  nan\n",
      "InternVL 3.5 30B A3B         | 0.421 | 0.332 | 0.584 | 0.264 ||  7.9 | 0.82 |  38.7s ||  nan |  nan\n",
      "Mistral Medium 3.1 (t=0.15)  | 0.412 | 0.352 | 0.499 | 0.278 || 10.4 | 0.79 |   3.3s ||  nan |  nan\n",
      "Qwen-VL Plus                 | 0.409 | 0.314 | 0.589 | 0.249 ||  8.0 | 0.79 |   3.6s || 0.01 | 0.44\n",
      "Mistral Medium 3.1 (t=1.00)  | 0.408 | 0.346 | 0.497 | 0.280 || 11.0 | 0.78 |   3.4s ||  nan |  nan\n",
      "Claude Sonnet 4.5            | 0.408 | 0.326 | 0.544 | 0.260 ||  9.1 | 0.79 |   6.3s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.00\n",
      "Claude Sonnet 4.5 (high)     | 0.407 | 0.343 | 0.501 | 0.258 || 10.4 | 0.79 |  17.0s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "InternVL 3.5 2B (think)      | 0.403 | 0.323 | 0.540 | 0.257 ||  8.8 | 0.79 |  30.4s ||  nan |  nan\n",
      "Gemma 27B                    | 0.402 | 0.343 | 0.489 | 0.256 || 11.1 | 0.75 |  10.5s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Claude Sonnet 4              | 0.397 | 0.311 | 0.548 | 0.253 ||  9.1 | 0.75 |   5.9s ||  nan |  nan\n",
      "Gemini 2.5 Flash Lite        | 0.396 | 0.359 | 0.453 | 0.272 || 10.9 | 0.83 | \u001b[1m\u001b[94m  3.0s\u001b[0m || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "Qwen3-VL 32B                 | 0.396 | 0.345 | 0.471 | 0.253 || 13.4 | 0.79 |  13.5s || 0.19 | 1.15\n",
      "Gemma 12B                    | 0.388 | 0.312 | 0.517 | 0.248 ||  9.7 | 0.75 |  13.3s || 0.02 | 0.47\n",
      "Qwen3-VL 30B A3B             | 0.381 | 0.326 | 0.485 | 0.245 ||  9.6 | 0.83 |   7.8s || 0.05 | 0.55\n",
      "InternVL 3.5 2B              | 0.380 | 0.297 | 0.547 | 0.234 ||  7.2 | 0.84 | \u001b[1m\u001b[91m121.1s\u001b[0m ||  nan |  nan\n",
      "Claude Haiku 4.5 (high)      | 0.378 | 0.330 | 0.444 | 0.242 || 12.7 | 0.73 |  15.3s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Claude Haiku 4.5             | 0.374 | 0.314 | 0.464 | 0.233 || 11.5 | 0.73 |   4.0s || \u001b[1m\u001b[94m0.00\u001b[0m | \u001b[1m\u001b[94m0.00\u001b[0m\n",
      "Qwen3-VL 8B                  | 0.370 | 0.339 | 0.443 | 0.264 ||  9.8 | 0.91 |   5.2s || 0.01 | 0.05\n",
      "GPT-4.1 nano                 | 0.363 | 0.285 | 0.505 | 0.216 ||  7.6 | 0.85 |   4.0s ||  nan |  nan\n",
      "Gemma 4B                     | 0.356 | 0.265 | 0.544 | 0.217 ||  7.4 | 0.78 |   3.2s || \u001b[1m\u001b[94m0.00\u001b[0m | 0.01\n",
      "Qwen3-VL 8B (think)          | \u001b[1m\u001b[91m0.330\u001b[0m | \u001b[1m\u001b[91m0.232\u001b[0m | 0.579 | \u001b[1m\u001b[91m0.194\u001b[0m ||  8.8 | 0.80 |  84.7s || \u001b[1m\u001b[91m0.31\u001b[0m | \u001b[1m\u001b[91m1.24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "text = write_results([base_path_coco, base_path_custom], [model_name_to_eval_dict_coco, model_name_to_eval_dict_custom], weights=[0.5, 0.5], latex=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22caa76-a568-4bb6-a392-a3bbf8fd4dcb",
   "metadata": {},
   "source": [
    "Models are sorted in descending order by F-1 score.<br>\n",
    "Best model(s) per column is/are highlighted in blue.<br>\n",
    "Worst model(s) per column is/are highlighted in red.<br>\n",
    "\n",
    "Legend:\n",
    "- F1: The achieved F-1 score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Rec.: The achieved recall score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Prec.: The achieved precision score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- mAP: The achieved mAP score of detections that passed label matching compared to groundtruth annotations.<br>\n",
    "- Ins.: The average number of object instances in a valid structured description per image.<br>\n",
    "- Mat.: The ratio of matched detections by the label matching procedure over all detections.<br>\n",
    "- Time: The median time to generate a valid structured description over all images.<br>\n",
    "- Fail: The rate of invalid structured descriptions after all (4) generation attempts.<br>\n",
    "- Ret.: The average number of retry attempts to generate a valid structured description per image (0 to 3).<br>\n",
    " \n",
    "Remarks:\n",
    "- Models where the last two columns report nan were evaluated with an infinite and untracked number of retry attempts, until a valid structured description was obtained.<br>\n",
    "- All models were used and interpreted at best effort, limiting parallel usage, attempting to extract JSON from within markdown tags or reasoning content, etc.<br>\n",
    "- Reasons for failed attempts may include rate limits, content moderation, timeouts, reaching max. token limits, etc.<br>\n",
    "- All reported times may heavily be affected by the used hardware, rate limits, server load, etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "278ae7a6-c2e3-4b95-af29-e50035e09e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_41_3104efbe_weighted.png'\n",
      "Results saved to '/home/paetzoldb0/ws/jazzy/main/src/vlm_gist/notebooks/evaluation/2025_10_31T12_48_41_3104efbe_weighted.txt'\n"
     ]
    }
   ],
   "source": [
    "save_results(text=text, suffix=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
